---
layout: post
title: 음원차트 가져오기
date: 2024-04-30 17:29 +0900
description: python
image: /assets/img/blog25.jpg
category: python 
tags: python
published: true
sitemap: true
---

오늘은 앞서 세팅한 python을 이용하여 음원차트 가져오는 방법에 대해 알아보도록 하겠습니다.

## 음원차트 가져오기
우선 전체 코드입니다. 전체적인 구조를 한번 체크해봅시다.
````python
import requests as req
from bs4 import BeautifulSoup as bs
import pandas as pd

head = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36'}
res = req.get("https://www.melon.com/chart/index.htm", headers=head)
soup = bs(res.text, "lxml")

ranking = soup.select("tbody .wrap.t_center > .rank")
title = soup.select("tbody .wrap_song_info .ellipsis.rank01 span > a")
artist = soup.select("tbody .wrap_song_info .ellipsis.rank02 span > a:nth-child(1)")


rankingList = []
titleList = []
artistList = []

print(len(ranking))
print(len(artist))
print(len(title))

rankingList = [r.text.strip() for r in ranking]
titleList = [t.text.strip() for t in title]
artistList = [a.text.strip() for a in artist]

chart_df = pd.DataFrame({
    'Ranking': rankingList,
    'Title': titleList,
    'Artist': artistList
})

chart_df.to_json("MelonChart100.json", force_ascii=False, orient="records")
````

## 라이브러리 Import
````python
import requests as req
from bs4 import BeautifulSoup as bs
import pandas as pd
````
라이브러리 Import: 코드의 첫 부분에서는 필요한 라이브러리들을 import 합니다.   
requests는 HTTP 요청을 보내고, BeautifulSoup는 HTML을 파싱하고 원하는 정보를 추출합니다.   
pandas는 데이터프레임을 다루기 위해 사용됩니다.   

## 사용자 에이전트 설정
````python
head = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36'}
````
head 변수에 사용자 에이전트 정보를 담아서 웹페이지에 HTTP 요청을 보낼 때 함께 보냅니다. 이는 웹페이지에 접근할 때 사용자 에이전트가 웹 브라우저인 것처럼 위장하기 위함입니다.

## 멜론 차트 페이지에 HTTP GET 요청 보내기
````python
res = req.get("https://www.melon.com/chart/index.htm", headers=head)
````
HTTP GET 요청 보내기: req.get() 함수를 사용하여 멜론 차트 페이지에 HTTP GET 요청을 보냅니다. 이때 headers 매개변수에는 위에서 설정한 사용자 에이전트 정보가 함께 전달됩니다.

## BeautifulSoup을 사용하여 HTML 파싱
````python
soup = bs(res.text, "lxml")
````
HTML 파싱: 요청한 웹페이지의 HTML을 BeautifulSoup을 사용하여 파싱합니다. 이렇게 하면 웹페이지의 구조를 파악하고 원하는 요소를 선택할 수 있습니다.

## 차트에서 순위, 제목, 아티스트를 추출하기 위해 CSS 선택자 사용
````python
ranking = soup.select("tbody .wrap.t_center > .rank")
title = soup.select("tbody .wrap_song_info .ellipsis.rank01 span > a")
artist = soup.select("tbody .wrap_song_info .ellipsis.rank02 span > a:nth-child(1)")
````
CSS 선택자를 사용한 데이터 추출: 멜론 차트에서 순위, 제목, 아티스트를 추출하기 위해 CSS 선택자를 사용합니다. select() 함수를 사용하여 선택자에 해당하는 요소들을 선택합니다.

## 추출한 데이터를 저장할 리스트 초기화
````python
rankingList = []
titleList = []
artistList = []
````

## 순위, 제목, 아티스트 리스트에 데이터 추가
````python
for r, t, a in zip(ranking, title, artist):
    rankingList.append(r.text.strip())
    titleList.append(t.text.strip())
    artistList.append(a.text.strip())
````
추출한 데이터를 리스트에 추가: for 루프를 사용하여 순위, 제목, 아티스트 정보를 순회하면서 각각의 정보를 리스트에 추가합니다.

## 데이터프레임 생성
````python
chart_df = pd.DataFrame({
    'Ranking': rankingList,
    'Title': titleList,
    'Artist': artistList
})
````
데이터프레임 생성: pd.DataFrame() 함수를 사용하여 추출한 데이터를 데이터프레임으로 만듭니다. 데이터프레임은 행과 열로 구성된 테이블 형태의 데이터 구조입니다.

## JSON 파일로 저장 
````python
chart_df.to_json("MelonChart100.json", force_ascii=False, orient="records")
````
JSON 파일로 저장: to_json() 메서드를 사용하여 데이터프레임을 JSON 파일로 저장합니다. 이때 force_ascii=False는 ASCII 문자만을 사용하지 않고 유니코드 문자를 그대로 사용하도록 합니다. orient="records"는 데이터를 레코드 단위로 저장하도록 지정합니다.

### 마무리
이렇게 차트를 크롤링하여 .json파일로 저장하는 것까지 해보았는데요. 이 방식을 이용하여 다양한 정보를 수집해세요.

# 감사합니다!
